{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9536b7a",
   "metadata": {},
   "source": [
    "# Using PEFT with custom models\n",
    "\n",
    "`peft` allows us to fine-tune models efficiently with LoRA. In this notebook we\n",
    "train a simple multilayer perceptron (MLP) using `peft`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64de581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "os.environ['BITSANDBYTES_NOWELCOME'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a1d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import peft\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd8ad3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10c1a3890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c981f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((1000, 20))\n",
    "y = (X.sum(1) > 10).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7861155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 800\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a06e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X[:n_train], y[:n_train]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X[n_train:], y[n_train:]),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_units_hidden=2000):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(20, num_units_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units_hidden, num_units_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units_hidden, 2),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb03a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002\n",
    "batch_size = 64\n",
    "max_epochs = 30\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e37e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, eval_dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for xb, yb in train_dataloader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            train_loss += loss.detach().float()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        for xb, yb in eval_dataloader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            eval_loss += loss.detach().float()\n",
    "\n",
    "        eval_loss_total = (eval_loss / len(eval_dataloader)).item()\n",
    "        train_loss_total = (train_loss / len(train_dataloader)).item()\n",
    "        print(f'{epoch=:<2} {train_loss_total=:.4f} {eval_loss_total=:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0fa2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training without PEFT\n",
    "module = MLP().to(device)\n",
    "optimizer = torch.optim.Adam(module.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42002230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0  train_loss_total=1.1008 eval_loss_total=0.6648\n",
      "epoch=1  train_loss_total=0.6641 eval_loss_total=0.6243\n",
      "epoch=2  train_loss_total=0.5475 eval_loss_total=0.5355\n",
      "epoch=3  train_loss_total=0.3885 eval_loss_total=0.3534\n",
      "epoch=4  train_loss_total=0.2576 eval_loss_total=0.4362\n",
      "epoch=5  train_loss_total=0.2201 eval_loss_total=0.2771\n",
      "epoch=6  train_loss_total=0.1514 eval_loss_total=0.2032\n",
      "epoch=7  train_loss_total=0.1173 eval_loss_total=0.2428\n",
      "epoch=8  train_loss_total=0.1057 eval_loss_total=0.2615\n",
      "epoch=9  train_loss_total=0.1137 eval_loss_total=0.2047\n",
      "epoch=10 train_loss_total=0.1334 eval_loss_total=0.3663\n",
      "epoch=11 train_loss_total=0.0925 eval_loss_total=0.3073\n",
      "epoch=12 train_loss_total=0.0603 eval_loss_total=0.2559\n",
      "epoch=13 train_loss_total=0.0520 eval_loss_total=0.1886\n",
      "epoch=14 train_loss_total=0.0511 eval_loss_total=0.2894\n",
      "epoch=15 train_loss_total=0.0324 eval_loss_total=0.2197\n",
      "epoch=16 train_loss_total=0.0177 eval_loss_total=0.2164\n",
      "epoch=17 train_loss_total=0.0156 eval_loss_total=0.2335\n",
      "epoch=18 train_loss_total=0.0086 eval_loss_total=0.2150\n",
      "epoch=19 train_loss_total=0.0071 eval_loss_total=0.2108\n",
      "epoch=20 train_loss_total=0.0055 eval_loss_total=0.2269\n",
      "epoch=21 train_loss_total=0.0049 eval_loss_total=0.2332\n",
      "epoch=22 train_loss_total=0.0042 eval_loss_total=0.2308\n",
      "epoch=23 train_loss_total=0.0040 eval_loss_total=0.2327\n",
      "epoch=24 train_loss_total=0.0035 eval_loss_total=0.2317\n",
      "epoch=25 train_loss_total=0.0033 eval_loss_total=0.2331\n",
      "epoch=26 train_loss_total=0.0029 eval_loss_total=0.2386\n",
      "epoch=27 train_loss_total=0.0027 eval_loss_total=0.2463\n",
      "epoch=28 train_loss_total=0.0023 eval_loss_total=0.2497\n",
      "epoch=29 train_loss_total=0.0021 eval_loss_total=0.2468\n",
      "CPU times: user 698 ms, sys: 170 ms, total: 868 ms\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%time train(module, optimizer, criterion, train_dataloader, eval_dataloader, epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa2835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', __main__.MLP),\n",
       " ('seq', torch.nn.modules.container.Sequential),\n",
       " ('seq.0', torch.nn.modules.linear.Linear),\n",
       " ('seq.1', torch.nn.modules.activation.ReLU),\n",
       " ('seq.2', torch.nn.modules.linear.Linear),\n",
       " ('seq.3', torch.nn.modules.activation.ReLU),\n",
       " ('seq.4', torch.nn.modules.linear.Linear),\n",
       " ('seq.5', torch.nn.modules.activation.LogSoftmax)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now training with PEFT\n",
    "[(n, type(m)) for n, m in MLP().named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2532c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = peft.LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=['seq.0', 'seq.2'],\n",
    "    modules_to_save=['seq.4']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f31b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 52,162 || all params: 4,100,164 || trainable%: 1.2722\n"
     ]
    }
   ],
   "source": [
    "module = MLP().to(device)\n",
    "module_copy = copy.deepcopy(module)\n",
    "peft_model = peft.get_peft_model(module, config)\n",
    "optimizer = torch.optim.Adam(peft_model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49f18cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0  train_loss_total=0.6777 eval_loss_total=0.6316\n",
      "epoch=1  train_loss_total=0.5815 eval_loss_total=0.5184\n",
      "epoch=2  train_loss_total=0.4233 eval_loss_total=0.3412\n",
      "epoch=3  train_loss_total=0.2959 eval_loss_total=0.3356\n",
      "epoch=4  train_loss_total=0.2465 eval_loss_total=0.3502\n",
      "epoch=5  train_loss_total=0.1848 eval_loss_total=0.2093\n",
      "epoch=6  train_loss_total=0.1341 eval_loss_total=0.2015\n",
      "epoch=7  train_loss_total=0.0906 eval_loss_total=0.2163\n",
      "epoch=8  train_loss_total=0.0855 eval_loss_total=0.2263\n",
      "epoch=9  train_loss_total=0.0631 eval_loss_total=0.2437\n",
      "epoch=10 train_loss_total=0.0471 eval_loss_total=0.2159\n",
      "epoch=11 train_loss_total=0.0299 eval_loss_total=0.2250\n",
      "epoch=12 train_loss_total=0.0273 eval_loss_total=0.3061\n",
      "epoch=13 train_loss_total=0.0669 eval_loss_total=0.7617\n",
      "epoch=14 train_loss_total=0.0843 eval_loss_total=0.5253\n",
      "epoch=15 train_loss_total=0.0643 eval_loss_total=0.2451\n",
      "epoch=16 train_loss_total=0.0136 eval_loss_total=0.2509\n",
      "epoch=17 train_loss_total=0.0061 eval_loss_total=0.2706\n",
      "epoch=18 train_loss_total=0.0033 eval_loss_total=0.2869\n",
      "epoch=19 train_loss_total=0.0023 eval_loss_total=0.2997\n",
      "epoch=20 train_loss_total=0.0019 eval_loss_total=0.2875\n",
      "epoch=21 train_loss_total=0.0014 eval_loss_total=0.2948\n",
      "epoch=22 train_loss_total=0.0012 eval_loss_total=0.2914\n",
      "epoch=23 train_loss_total=0.0010 eval_loss_total=0.2987\n",
      "epoch=24 train_loss_total=0.0009 eval_loss_total=0.3023\n",
      "epoch=25 train_loss_total=0.0007 eval_loss_total=0.3084\n",
      "epoch=26 train_loss_total=0.0006 eval_loss_total=0.3195\n",
      "epoch=27 train_loss_total=0.0005 eval_loss_total=0.3247\n",
      "epoch=28 train_loss_total=0.0004 eval_loss_total=0.3305\n",
      "epoch=29 train_loss_total=0.0004 eval_loss_total=0.3403\n",
      "CPU times: user 698 ms, sys: 144 ms, total: 842 ms\n",
      "Wall time: 1.76 s\n"
     ]
    }
   ],
   "source": [
    "%time train(peft_model, optimizer, criterion, train_dataloader, eval_dataloader, epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bcfd2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new params: model.seq.0.lora_A.default.weight |   160 parameters | updated\n",
      "new params: model.seq.0.lora_B.default.weight | 16000 parameters | updated\n",
      "new params: model.seq.2.lora_A.default.weight | 16000 parameters | updated\n",
      "new params: model.seq.2.lora_B.default.weight | 16000 parameters | updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if 'lora' not in name:\n",
    "        continue\n",
    "    print(f'new params: {name:<13} | {param.numel():>5} parameters | updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca51c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter seq.0.weight  |   40000 parameters | not updated\n",
      "Parameter seq.0.bias    |    2000 parameters | not updated\n",
      "Parameter seq.2.weight  | 4000000 parameters | not updated\n",
      "Parameter seq.2.bias    |    2000 parameters | not updated\n",
      "Parameter seq.4.weight  |    4000 parameters | not updated\n",
      "Parameter seq.4.bias    |       2 parameters | not updated\n",
      "Parameter seq.4.weight  |    4000 parameters | updated\n",
      "Parameter seq.4.bias    |       2 parameters | updated\n"
     ]
    }
   ],
   "source": [
    "params_before = dict(module_copy.named_parameters())\n",
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        continue\n",
    "    name_before = (\n",
    "        name.partition(\".\")[-1].replace(\"base_layer.\", \"\").replace(\"original_\",\n",
    "                                                                   \"\").replace(\"module.\", \"\").replace(\"modules_to_save.default.\", \"\")\n",
    "    )\n",
    "    param_before = params_before[name_before]\n",
    "    if torch.allclose(param, param_before):\n",
    "        print(\n",
    "            f\"Parameter {name_before:<13} | {param.numel():>7} parameters | not updated\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Parameter {name_before:<13} | {param.numel():>7} parameters | updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdbdd385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49dd759354344a6a329b132ae2dde2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70fffab614940b182168b8eee5833e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/rodmosc/peft-lora-with-custom-model/commit/a5a87a86b6235e8eb5a4edf90f71d2134a9b0a23', commit_message='Upload model', commit_description='', oid='a5a87a86b6235e8eb5a4edf90f71d2134a9b0a23', pr_url=None, repo_url=RepoUrl('https://huggingface.co/rodmosc/peft-lora-with-custom-model', endpoint='https://huggingface.co', repo_type='model', repo_id='rodmosc/peft-lora-with-custom-model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 'rodmosc'\n",
    "model_name = 'peft-lora-with-custom-model'\n",
    "model_id = f'{user}/{model_name}'\n",
    "peft_model.push_to_hub(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8253392e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5decb762274483e9923f10717753901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/903 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37eedd0a46b4998bc0f8a8cee989a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/209k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "peft.peft_model.PeftModel"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = peft.PeftModel.from_pretrained(module_copy, model_id)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d9b216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_peft = peft_model(X.to(device))\n",
    "y_model = model(X.to(device))\n",
    "torch.allclose(y_peft, y_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
